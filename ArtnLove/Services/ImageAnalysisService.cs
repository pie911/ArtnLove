using Microsoft.Extensions.Options;
using Microsoft.ML.OnnxRuntime;
using Microsoft.ML.OnnxRuntime.Tensors;
using SixLabors.ImageSharp;
using SixLabors.ImageSharp.PixelFormats;
using SixLabors.ImageSharp.Processing;

namespace ArtnLove.Services;

public class ImageAnalysisResult
{
    public string[] Tags { get; set; } = Array.Empty<string>();
    public string Style { get; set; } = string.Empty;
    public string Description { get; set; } = string.Empty;
    public float Confidence { get; set; }
}

/// <summary>
/// ImageAnalysisService: loads an ONNX model (path from config) and runs inference.
/// This is a scaffold: exact preprocessing and outputs depend on your exported model.
/// If no model is present, returns placeholder analysis and logs a warning.
/// </summary>
public class ImageAnalysisService : IDisposable
{
    private readonly ILogger<ImageAnalysisService> _logger;
    private readonly string _modelPath;
    private InferenceSession? _session;
    private readonly object _lock = new();

    public ImageAnalysisService(IConfiguration configuration, ILogger<ImageAnalysisService> logger)
    {
        _logger = logger;
        _modelPath = configuration["ML_MODEL_PATH"] ?? configuration.GetValue<string>("ML:ModelPath") ?? string.Empty;
        TryInitialize();
    }

    private void TryInitialize()
    {
        if (string.IsNullOrEmpty(_modelPath))
        {
            _logger.LogWarning("ML model path not configured (ML_MODEL_PATH). ImageAnalysis will return placeholders.");
            return;
        }

        if (!File.Exists(_modelPath))
        {
            _logger.LogWarning("ML model file not found at {ModelPath}. ImageAnalysis will return placeholders.", _modelPath);
            return;
        }

        lock (_lock)
        {
            if (_session != null) return;
            try
            {
                _session = new InferenceSession(_modelPath);
                _logger.LogInformation("Loaded ONNX model from {ModelPath}", _modelPath);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to load ONNX model");
            }
        }
    }

    public async Task<ImageAnalysisResult> AnalyzeAsync(Stream imageStream, CancellationToken ct = default)
    {
        // If no session, return placeholders
        if (_session == null)
        {
            _logger.LogWarning("ONNX session not initialized; returning placeholder analysis.");
            return await Task.FromResult(new ImageAnalysisResult
            {
                Tags = new[] { "abstract", "colorful" },
                Style = "unknown",
                Description = "Autogenerated description (placeholder)",
                Confidence = 0.0f
            });
        }

        try
        {
            // Preprocess image into tensor (example: resize to 224x224, normalize)
            using var image = await Image.LoadAsync<Rgba32>(imageStream, ct);
            image.Mutate(x => x.Resize(new ResizeOptions { Size = new Size(224, 224), Mode = ResizeMode.Crop }));

            // Create tensor [1,3,224,224]
            var input = new DenseTensor<float>(new[] { 1, 3, 224, 224 });
            for (int y = 0; y < 224; y++)
            {
                for (int x = 0; x < 224; x++)
                {
                    var p = image[x, y];
                    // Normalize to 0..1
                    input[0, 0, y, x] = p.R / 255f;
                    input[0, 1, y, x] = p.G / 255f;
                    input[0, 2, y, x] = p.B / 255f;
                }
            }

            var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", input) };
            using var results = _session.Run(inputs);

            // NOTE: postprocessing depends on your model's outputs; here's a generic stub.
            var first = results.FirstOrDefault();
            var result = new ImageAnalysisResult();
            if (first != null)
            {
                // If output is a tensor of floats (e.g., classification probabilities)
                if (first.Value is Tensor<float> tf)
                {
                    // pick top-k as tags (placeholder mapping)
                    var probs = tf.ToArray();
                    var topIndex = Array.IndexOf(probs, probs.Max());
                    result.Tags = new[] { $"tag_{topIndex}" };
                    result.Confidence = probs.Max();
                    result.Description = $"Predicted tag_{topIndex} (confidence {result.Confidence:F2})";
                    result.Style = "predicted-style";
                }
                else
                {
                    result.Description = "Model returned unknown output format";
                }
            }
            else
            {
                result.Description = "No outputs from model";
            }

            return result;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Image analysis failed");
            return new ImageAnalysisResult { Description = "Error during analysis" };
        }
    }

    public void Dispose()
    {
        _session?.Dispose();
    }
}
